{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izKXA4b6-oIv",
        "outputId": "ede22721-eb64-48e0-a2ef-26f02674577c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Span-ASTE'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 168 (delta 44), reused 47 (delta 30), pack-reused 94\u001b[K\n",
            "Receiving objects: 100% (168/168), 578.23 KiB | 23.13 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n",
            "Note: checking out '16c7937'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 16c7937 Debug extra keys in SpanModel\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Cython==0.29.21\n",
            "  Downloading Cython-0.29.21-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 31.7 MB/s \n",
            "\u001b[?25hCollecting PYEVALB==0.1.3\n",
            "  Downloading PYEVALB-0.1.3-py3-none-any.whl (13 kB)\n",
            "Collecting allennlp-models==1.2.2\n",
            "  Downloading allennlp_models-1.2.2-py3-none-any.whl (353 kB)\n",
            "\u001b[K     |████████████████████████████████| 353 kB 61.2 MB/s \n",
            "\u001b[?25hCollecting allennlp==1.2.2\n",
            "  Downloading allennlp-1.2.2-py3-none-any.whl (505 kB)\n",
            "\u001b[K     |████████████████████████████████| 505 kB 67.3 MB/s \n",
            "\u001b[?25hCollecting botocore==1.19.46\n",
            "  Downloading botocore-1.19.46-py2.py3-none-any.whl (7.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2 MB 49.1 MB/s \n",
            "\u001b[?25hCollecting fire==0.3.1\n",
            "  Downloading fire-0.3.1.tar.gz (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting nltk==3.6.6\n",
            "  Downloading nltk-3.6.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 57.6 MB/s \n",
            "\u001b[?25hCollecting numpy==1.21.5\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 68.4 MB/s \n",
            "\u001b[?25hCollecting pandas==1.1.5\n",
            "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 57.8 MB/s \n",
            "\u001b[?25hCollecting pydantic==1.6.2\n",
            "  Downloading pydantic-1.6.2-cp37-cp37m-manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 51.2 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.2.post1\n",
            "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 52.8 MB/s \n",
            "\u001b[?25hCollecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.6 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 48.2 MB/s \n",
            "\u001b[?25hCollecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 45.4 MB/s \n",
            "\u001b[?25hCollecting boto3==1.16.46\n",
            "  Downloading boto3-1.16.46-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 74.8 MB/s \n",
            "\u001b[?25hCollecting pytablewriter>=0.10.2\n",
            "  Downloading pytablewriter-0.64.2-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 72.5 MB/s \n",
            "\u001b[?25hCollecting conllu==4.2.1\n",
            "  Downloading conllu-4.2.1-py2.py3-none-any.whl (14 kB)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Collecting py-rouge==1.1\n",
            "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.19.1.tar.gz (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 61.4 MB/s \n",
            "\u001b[?25hCollecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 65.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.6.4)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (2.23.0)\n",
            "Collecting spacy<2.4,>=2.1.0\n",
            "  Downloading spacy-2.3.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8 MB 69.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (4.64.1)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.1.0)\n",
            "Collecting filelock<3.1,>=3.0\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.19.46->-r requirements.txt (line 5)) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 65.7 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (2022.6.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r requirements.txt (line 9)) (2022.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (0.16.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (4.1.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1->-r requirements.txt (line 13)) (7.1.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (3.19.6)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 61.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 47.4 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (21.3)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting mbstrdecoder<2,>=1.0.0\n",
            "  Downloading mbstrdecoder-1.1.1-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.7/dist-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (57.4.0)\n",
            "Collecting tabledata<2,>=1.3.0\n",
            "  Downloading tabledata-1.3.0-py3-none-any.whl (11 kB)\n",
            "Collecting pathvalidate<3,>=2.3.0\n",
            "  Downloading pathvalidate-2.5.2-py3-none-any.whl (20 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5\n",
            "  Downloading tcolorpy-0.1.2-py3-none-any.whl (7.9 kB)\n",
            "Collecting typepy[datetime]<2,>=1.2.0\n",
            "  Downloading typepy-1.3.0-py3-none-any.whl (31 kB)\n",
            "Collecting DataProperty<2,>=0.55.0\n",
            "  Downloading DataProperty-0.55.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (2.10)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 64.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (2022.9.24)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.9)\n",
            "Collecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.10.1)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 59.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (3.0.8)\n",
            "Collecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.7.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp-models==1.2.2->-r requirements.txt (line 3)) (0.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==1.2.2->-r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle->allennlp==1.2.2->-r requirements.txt (line 4)) (4.13.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 14)) (3.0.9)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (22.1.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (9.0.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.11.0)\n",
            "Building wheels for collected packages: fire, overrides, jsonnet, word2number, sacremoses\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111022 sha256=b8cd4990b02d9e104455bfe2d5513371f35e60d5190cd4ecf9727a011a4561d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/38/e1/8b62337a8ecf5728bdc1017e828f253f7a9cf25db999861bec\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10188 sha256=36d5b6a01b0150bd9cb88f010fcc60f9f577102b4fa3d9cde2800b89a7cdc512\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.19.1-cp37-cp37m-linux_x86_64.whl size=3997197 sha256=e22023b827fe00e9643ae0ee97d1082af63546bc2bc87868df5c8cdc1f9c5e8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/6b/48/a168ed5f8d01c50268605eff341c29126286763607bf707e3b\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5580 sha256=bf061f8bc19c2cee7fcbda4f96693e6ae38dab302e4a5a847ab4b0b74227b2d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=361ca9e2b9763c83d590ff60ba829cbf563a519ca73d2d64e6a82d688814f269\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built fire overrides jsonnet word2number sacremoses\n",
            "Installing collected packages: mbstrdecoder, urllib3, typepy, numpy, jmespath, srsly, plac, catalogue, botocore, tokenizers, thinc, sentencepiece, sacremoses, s3transfer, filelock, DataProperty, dataclasses, transformers, torch, tensorboardX, tcolorpy, tabledata, spacy, scikit-learn, pathvalidate, overrides, nltk, jsonpickle, jsonnet, boto3, word2number, pytablewriter, py-rouge, ftfy, conllu, allennlp, torchvision, PYEVALB, pydantic, pandas, fire, Cython, allennlp-models\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.5\n",
            "    Uninstalling srsly-2.4.5:\n",
            "      Successfully uninstalled srsly-2.4.5\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.8\n",
            "    Uninstalling catalogue-2.0.8:\n",
            "      Successfully uninstalled catalogue-2.0.8\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.5\n",
            "    Uninstalling thinc-8.1.5:\n",
            "      Successfully uninstalled thinc-8.1.5\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.8.0\n",
            "    Uninstalling filelock-3.8.0:\n",
            "      Successfully uninstalled filelock-3.8.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.2\n",
            "    Uninstalling spacy-3.4.2:\n",
            "      Successfully uninstalled spacy-3.4.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.2\n",
            "    Uninstalling pydantic-1.10.2:\n",
            "      Successfully uninstalled pydantic-1.10.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 0.29.32\n",
            "    Uninstalling Cython-0.29.32:\n",
            "      Successfully uninstalled Cython-0.29.32\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.8 which is incompatible.\n",
            "confection 0.0.3 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 1.6.2 which is incompatible.\n",
            "confection 0.0.3 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\u001b[0m\n",
            "Successfully installed Cython-0.29.21 DataProperty-0.55.0 PYEVALB-0.1.3 allennlp-1.2.2 allennlp-models-1.2.2 boto3-1.16.46 botocore-1.19.46 catalogue-1.0.2 conllu-4.2.1 dataclasses-0.6 filelock-3.0.12 fire-0.3.1 ftfy-6.1.1 jmespath-0.10.0 jsonnet-0.19.1 jsonpickle-2.2.0 mbstrdecoder-1.1.1 nltk-3.6.6 numpy-1.21.5 overrides-3.1.0 pandas-1.1.5 pathvalidate-2.5.2 plac-1.1.3 py-rouge-1.1 pydantic-1.6.2 pytablewriter-0.64.2 s3transfer-0.3.7 sacremoses-0.0.53 scikit-learn-0.22.2.post1 sentencepiece-0.1.97 spacy-2.3.8 srsly-1.0.6 tabledata-1.3.0 tcolorpy-0.1.2 tensorboardX-2.5.1 thinc-7.4.6 tokenizers-0.9.2 torch-1.7.0 torchvision-0.8.1 transformers-3.4.0 typepy-1.3.0 urllib3-1.25.11 word2number-1.1\n",
            "Found existing installation: dataclasses 0.6\n",
            "Uninstalling dataclasses-0.6:\n",
            "  Successfully uninstalled dataclasses-0.6\n",
            "Archive:  data.zip\n",
            "   creating: aste/data/\n",
            "   creating: aste/data/triplet_data/\n",
            "   creating: aste/data/triplet_data/14lap/\n",
            "  inflating: aste/data/triplet_data/14lap/dev.txt  \n",
            "  inflating: aste/data/triplet_data/14lap/test.txt  \n",
            "  inflating: aste/data/triplet_data/14lap/train.txt  \n",
            "   creating: aste/data/triplet_data/14res/\n",
            "  inflating: aste/data/triplet_data/14res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/14res/test.txt  \n",
            "  inflating: aste/data/triplet_data/14res/train.txt  \n",
            "   creating: aste/data/triplet_data/15res/\n",
            "  inflating: aste/data/triplet_data/15res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/15res/test.txt  \n",
            "  inflating: aste/data/triplet_data/15res/train.txt  \n",
            "   creating: aste/data/triplet_data/16res/\n",
            "  inflating: aste/data/triplet_data/16res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/16res/test.txt  \n",
            "  inflating: aste/data/triplet_data/16res/train.txt  \n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chiayewken/Span-ASTE.git\n",
        "# !cd Span-ASTE && git checkout 7cbf035\n",
        "# !cd Span-ASTE && git checkout 92bc9a0\n",
        "!cd Span-ASTE && git checkout 16c7937\n",
        "!cp -a Span-ASTE/* .\n",
        "!echo boto3==1.16.46 >> requirements.txt\n",
        "!bash setup.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pTnCgDxcSQ5",
        "outputId": "5907f7cb-531d-41a4-a75c-054e5243a5d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: ['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.']\n",
            "target: (16, 17)\n",
            "opinion: (15, 15)\n",
            "label: LabelEnum.positive\n",
            "\n",
            "tokens: ['it', 'is', 'of', 'high', 'quality', ',', 'has', 'a', 'killer', 'GUI', ',', 'is', 'extremely', 'stable', ',', 'is', 'highly', 'expandable', ',', 'is', 'bundled', 'with', 'lots', 'of', 'very', 'good', 'applications', ',', 'is', 'easy', 'to', 'use', ',', 'and', 'is', 'absolutely', 'gorgeous', '.']\n",
            "target: (4, 4)\n",
            "opinion: (3, 3)\n",
            "label: LabelEnum.positive\n",
            "target: (9, 9)\n",
            "opinion: (8, 8)\n",
            "label: LabelEnum.positive\n",
            "target: (26, 26)\n",
            "opinion: (25, 25)\n",
            "label: LabelEnum.positive\n",
            "target: (31, 31)\n",
            "opinion: (29, 29)\n",
            "label: LabelEnum.positive\n",
            "\n",
            "tokens: ['Easy', 'to', 'start', 'up', 'and', 'does', 'not', 'overheat', 'as', 'much', 'as', 'other', 'laptops', '.']\n",
            "target: (2, 3)\n",
            "opinion: (0, 0)\n",
            "label: LabelEnum.positive\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Data Exploration\n",
        "data_name = \"14lap\" #@param [\"14lap\", \"14res\", \"15res\", \"16res\"]\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"aste\")\n",
        "from data_utils import Data\n",
        "\n",
        "path = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
        "data = Data.load_from_full_path(path)\n",
        "\n",
        "for s in data.sentences[:3]:\n",
        "    print(\"tokens:\", s.tokens)\n",
        "    for t in s.triples:\n",
        "        print(\"target:\", (t.t_start, t.t_end))\n",
        "        print(\"opinion:\", (t.o_start, t.o_end))\n",
        "        print(\"label:\", t.label)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained SpanModel weights\n",
        "from pathlib import Path\n",
        "template = \"https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/{}.tar\"\n",
        "url = template.format(data_name)\n",
        "model_tar = Path(url).name\n",
        "model_dir = Path(url).stem\n",
        "\n",
        "!wget -nc $url\n",
        "!tar -xf $model_tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LmrJekiPHpQ",
        "outputId": "5cbed6cd-bf36-4532-8cc3-6fd27ea2a82e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘14lap.tar’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488,
          "referenced_widgets": [
            "06ce7feacbfc47e696b005bda7d6fc52",
            "7e7961cebbbd4af988eadca9ebbc72a8",
            "57bf9771c66f48fb89f29c2138d64101",
            "df4cef36d642490eb23f0db462d8acf5",
            "ae3a872a5e084ae79d393a45bb4e75bb",
            "f989b846ca904d818d1c48c7fc43a301",
            "058ba503b3e3485298c0e84b3eb831f7",
            "bbd916234f834a61b154c6d1cbc16093",
            "4ff50cf0303e4f32b111582a8f1a7204",
            "be21ffc26a88423fa04274598782ca94",
            "13ae0428359f4af79ba13401d4b6a671",
            "b249aa7368d048a1aa0bb26fef197a3a",
            "978289baa03e4a728c91767e682c1e58",
            "53f0e9654c42432c936a7be756c2f1ad",
            "373b2bbdd6094405b5a3781e3ce8b854",
            "e17fae11370d48469a43723103510276",
            "d2137a1d41bf4654b2321b0e8b3179ea",
            "9819a63af0f349f3b7eda83464325600",
            "4ed85ff4e68d4c258dc7fc7a5eb60a0f",
            "9df7921ab61b4a8698e5dff835fd1ada",
            "68dcb517716848faaa1196b40d011954",
            "9739ad3b7a894a76956a305a5505c84f",
            "a1759abf000f433dbbcd8e3ace643b0c",
            "5e3e35bc02f9405fb467ba7cd1aee340",
            "3ee51e2dcd654f2caff137cff38f8bc9",
            "13cc94dcb00a470a87aaf3409b20a605",
            "c5f32837a20b480eb4f75f7ba357e443",
            "9ebd2d576b044d7aac22e3ef1cd7bf49",
            "8f1e31c6b0094f6a80da012841845920",
            "cad43e17e0194a9da9586158788e6757",
            "32b38abe23a74a569a3fe0895a36d54e",
            "2cf108605bd54f87a2ca6a5f505926df",
            "b64601c0d3d3465d8334080f24c50138",
            "46d6b1110d3d428d940f7b169250313f",
            "6f6f97e61db74ac8b351a2836191f15d",
            "119ea25862a6424dbd0281cc394dc215",
            "627a0977de4349019428352c7e9b9243",
            "3f6347036fe0464a8aead0d7fec311b2",
            "343bbfb6096d4dde9b415b7eae198e68",
            "c2b9230207404a03b87b1da87978873e",
            "afef86df3231491d9ff5ec09b5b7856b",
            "ccb2ccd455ae477d837e36f23bc185ec",
            "3192fada7cdc48719da3f03d31dc52f1",
            "68805c09bfc44d86a2f5d99cacc7551f"
          ]
        },
        "id": "r3i4rnIhapWe",
        "outputId": "c8d0d04b-ddd7-4f63-846f-f159bf080b35"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06ce7feacbfc47e696b005bda7d6fc52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b249aa7368d048a1aa0bb26fef197a3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1759abf000f433dbbcd8e3ace643b0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################################\n",
            "################################################################################\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46d6b1110d3d428d940f7b169250313f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n",
            "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "{'unused_keys': dict_keys([])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7fcdb2c21ef0>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading instances: 1it [00:00, 193.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{'target': 'Windows 8', 'opinion': 'Did not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n",
            "\n",
            "{'target': 'touchscreen functions', 'opinion': 'Did not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n",
            "\n",
            "{'target': 'Windows 8', 'opinion': 'new', 'sentiment': <LabelEnum.neutral: 'NEU'>}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Use pretrained SpanModel weights for prediction\n",
        "import sys\n",
        "sys.path.append(\"aste\")\n",
        "from pathlib import Path\n",
        "from data_utils import Data, Sentence, SplitEnum\n",
        "from wrapper import SpanModel\n",
        "\n",
        "def predict_sentence(text: str, model: SpanModel) -> Sentence:\n",
        "    path_in = \"temp_in.txt\"\n",
        "    path_out = \"temp_out.txt\"\n",
        "    sent = Sentence(tokens=text.split(), triples=[], pos=[], is_labeled=False, weight=1, id=0)\n",
        "    data = Data(root=Path(), data_split=SplitEnum.test, sentences=[sent])\n",
        "    data.save_to_path(path_in)\n",
        "    model.predict(path_in, path_out)\n",
        "    data = Data.load_from_full_path(path_out)\n",
        "    return data.sentences[0]\n",
        "\n",
        "text = \"Did not enjoy the new Windows 8 and touchscreen functions .\"\n",
        "model = SpanModel(save_dir=model_dir, random_seed=0)\n",
        "sent = predict_sentence(text, model)\n",
        "\n",
        "for t in sent.triples:\n",
        "    target = \" \".join(sent.tokens[t.t_start:t.t_end+1])\n",
        "    opinion = \" \".join(sent.tokens[t.o_start:t.o_end+1])\n",
        "    print()\n",
        "    print(dict(target=target, opinion=opinion, sentiment=t.label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srSNwqUz-39x",
        "outputId": "ea64d480-1136-4e88-c0c6-e44eb28805d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'weights_dir': PosixPath('outputs/14lap/seed_4/weights')}\n",
            "{'random_seed': 4}\n",
            "{'pytorch_seed': 4}\n",
            "{'numpy_seed': 4}\n",
            "{'train_data_path': PosixPath('/content/outputs/14lap/seed_4/temp_data/train.json')}\n",
            "{'validation_data_path': PosixPath('/content/outputs/14lap/seed_4/temp_data/validation.json')}\n",
            "{'test_data_path': PosixPath('/content/outputs/14lap/seed_4/temp_data/test.json')}\n",
            "{'path_config': PosixPath('outputs/14lap/seed_4/config.jsonnet')}\n",
            "{'command': 'cd /content && allennlp train outputs/14lap/seed_4/config.jsonnet --serialization-dir outputs/14lap/seed_4/weights --include-package span_model'}\n",
            "2022-08-19 08:19:26,409 - INFO - allennlp.common.params - random_seed = 4\n",
            "2022-08-19 08:19:26,409 - INFO - allennlp.common.params - numpy_seed = 4\n",
            "2022-08-19 08:19:26,409 - INFO - allennlp.common.params - pytorch_seed = 4\n",
            "2022-08-19 08:19:26,412 - INFO - allennlp.common.checks - Pytorch version: 1.7.0\n",
            "2022-08-19 08:19:26,412 - INFO - allennlp.common.params - type = default\n",
            "2022-08-19 08:19:26,413 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
            "2022-08-19 08:19:26,414 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-08-19 08:19:26,414 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2022-08-19 08:19:26,414 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2022-08-19 08:19:26,414 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2022-08-19 08:19:26,414 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2022-08-19 08:19:26,414 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
            "2022-08-19 08:19:26,415 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
            "2022-08-19 08:19:26,415 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
            "2022-08-19 08:19:26,416 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
            "2022-08-19 08:19:26,416 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
            "2022-08-19 08:19:26,416 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
            "2022-08-19 08:19:26,416 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
            "################################################################################\n",
            "2022-08-19 08:19:32,196 - INFO - allennlp.common.params - train_data_path = /content/outputs/14lap/seed_4/temp_data/train.json\n",
            "2022-08-19 08:19:32,197 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f69ae09d950>\n",
            "2022-08-19 08:19:32,197 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
            "2022-08-19 08:19:32,197 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2022-08-19 08:19:32,197 - INFO - allennlp.common.params - validation_data_path = /content/outputs/14lap/seed_4/temp_data/validation.json\n",
            "2022-08-19 08:19:32,197 - INFO - allennlp.common.params - validation_data_loader = None\n",
            "2022-08-19 08:19:32,197 - INFO - allennlp.common.params - test_data_path = /content/outputs/14lap/seed_4/temp_data/test.json\n",
            "2022-08-19 08:19:32,197 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2022-08-19 08:19:32,198 - INFO - allennlp.common.params - batch_weight_key =\n",
            "2022-08-19 08:19:32,198 - INFO - allennlp.training.util - Reading training data from /content/outputs/14lap/seed_4/temp_data/train.json\n",
            "{'file_path': '/content/outputs/14lap/seed_4/temp_data/train.json', 'stats': Stats(entity_total=2548, entity_drop=0, relation_total=1460, relation_drop=0, graph_total=0, graph_edges=0, grid_total=438060, grid_paired=2274)}\n",
            "2022-08-19 08:19:33,494 - INFO - allennlp.training.util - Reading validation data from /content/outputs/14lap/seed_4/temp_data/validation.json\n",
            "{'file_path': '/content/outputs/14lap/seed_4/temp_data/validation.json', 'stats': Stats(entity_total=600, entity_drop=0, relation_total=345, relation_drop=0, graph_total=0, graph_edges=0, grid_total=107881, grid_paired=553)}\n",
            "2022-08-19 08:19:33,651 - INFO - allennlp.training.util - Reading test data from /content/outputs/14lap/seed_4/temp_data/test.json\n",
            "{'file_path': '/content/outputs/14lap/seed_4/temp_data/test.json', 'stats': Stats(entity_total=600, entity_drop=0, relation_total=345, relation_drop=0, graph_total=0, graph_edges=0, grid_total=107881, grid_paired=553)}\n",
            "2022-08-19 08:19:34,050 - INFO - allennlp.common.params - type = from_instances\n",
            "2022-08-19 08:19:34,050 - INFO - allennlp.common.params - min_count = None\n",
            "2022-08-19 08:19:34,051 - INFO - allennlp.common.params - max_vocab_size = None\n",
            "2022-08-19 08:19:34,051 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
            "2022-08-19 08:19:34,051 - INFO - allennlp.common.params - pretrained_files = None\n",
            "2022-08-19 08:19:34,051 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
            "2022-08-19 08:19:34,051 - INFO - allennlp.common.params - tokens_to_add = None\n",
            "2022-08-19 08:19:34,051 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
            "2022-08-19 08:19:34,051 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
            "2022-08-19 08:19:34,051 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
            "2022-08-19 08:19:34,051 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "2022-08-19 08:19:34,124 - INFO - allennlp.common.params - model.type = span_model\n",
            "2022-08-19 08:19:34,124 - INFO - allennlp.common.params - model.embedder.type = basic\n",
            "2022-08-19 08:19:34,125 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
            "2022-08-19 08:19:34,125 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased\n",
            "2022-08-19 08:19:34,125 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
            "2022-08-19 08:19:34,126 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
            "2022-08-19 08:19:34,126 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
            "2022-08-19 08:19:34,126 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
            "2022-08-19 08:19:34,126 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
            "2022-08-19 08:19:34,126 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
            "2022-08-19 08:19:37,890 - INFO - allennlp.common.params - model.modules.ner.focal_loss_gamma = 2\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.ner.neg_class_weight = -1\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.ner.use_bi_affine = False\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.ner.use_double_scorer = False\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.ner.use_focal_loss = False\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.ner.use_gold_for_train_prune_scores = False\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.ner.use_single_pool = False\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.relation.focal_loss_gamma = 2\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.relation.neg_class_weight = -1\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.relation.span_length_loss_weight_gamma = 0\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.relation.use_bag_pair_scorer = False\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_classifier = False\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_pruner = False\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_v2 = False\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.relation.use_classify_mask_pruner = False\n",
            "2022-08-19 08:19:37,891 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_focal_loss = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_ner_scores_for_prune = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_ope_down_project = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_cls = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_maxpool = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_multiply = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_pairwise_down_project = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_single_pool = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_span_loss_for_pruners = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task_after_prune = False\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.feature_size = 20\n",
            "2022-08-19 08:19:37,892 - INFO - allennlp.common.params - model.max_span_width = 8\n",
            "2022-08-19 08:19:37,893 - INFO - allennlp.common.params - model.target_task = relation\n",
            "2022-08-19 08:19:37,893 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal\n",
            "2022-08-19 08:19:37,894 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0\n",
            "2022-08-19 08:19:37,894 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None\n",
            "2022-08-19 08:19:37,894 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
            "2022-08-19 08:19:37,895 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
            "2022-08-19 08:19:37,895 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
            "2022-08-19 08:19:37,895 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
            "2022-08-19 08:19:37,895 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
            "2022-08-19 08:19:37,896 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2022-08-19 08:19:37,896 - INFO - allennlp.common.params - model.display_metrics = None\n",
            "2022-08-19 08:19:37,896 - INFO - allennlp.common.params - model.use_ner_embeds = False\n",
            "2022-08-19 08:19:37,896 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
            "2022-08-19 08:19:37,896 - INFO - allennlp.common.params - model.use_double_mix_embedder = False\n",
            "2022-08-19 08:19:37,896 - INFO - allennlp.common.params - model.relation_head_type = proper\n",
            "2022-08-19 08:19:37,896 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
            "2022-08-19 08:19:37,896 - INFO - allennlp.common.params - model.use_bilstm_after_embedder = False\n",
            "{'locals': ('use_ner_embeds', False)}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_double_mix_embedder', False)}\n",
            "{'locals': ('relation_head_type', 'proper')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "2022-08-19 08:19:37,897 - INFO - allennlp.common.params - ner.regularizer = None\n",
            "2022-08-19 08:19:37,897 - INFO - allennlp.common.params - ner.use_bi_affine = False\n",
            "2022-08-19 08:19:37,897 - INFO - allennlp.common.params - ner.neg_class_weight = -1\n",
            "2022-08-19 08:19:37,897 - INFO - allennlp.common.params - ner.use_focal_loss = False\n",
            "2022-08-19 08:19:37,897 - INFO - allennlp.common.params - ner.focal_loss_gamma = 2\n",
            "2022-08-19 08:19:37,898 - INFO - allennlp.common.params - ner.use_double_scorer = False\n",
            "2022-08-19 08:19:37,898 - INFO - allennlp.common.params - ner.use_gold_for_train_prune_scores = False\n",
            "2022-08-19 08:19:37,898 - INFO - allennlp.common.params - ner.use_single_pool = False\n",
            "2022-08-19 08:19:37,898 - INFO - allennlp.common.params - ner.name = ner_labels\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "2022-08-19 08:19:37,903 - INFO - allennlp.common.params - relation.regularizer = None\n",
            "2022-08-19 08:19:37,903 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
            "2022-08-19 08:19:37,903 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
            "2022-08-19 08:19:37,903 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
            "2022-08-19 08:19:37,904 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
            "2022-08-19 08:19:37,904 - INFO - allennlp.common.params - relation.use_pair_feature_maxpool = False\n",
            "2022-08-19 08:19:37,904 - INFO - allennlp.common.params - relation.use_pair_feature_cls = False\n",
            "2022-08-19 08:19:37,904 - INFO - allennlp.common.params - relation.use_bi_affine_classifier = False\n",
            "2022-08-19 08:19:37,904 - INFO - allennlp.common.params - relation.neg_class_weight = -1\n",
            "2022-08-19 08:19:37,904 - INFO - allennlp.common.params - relation.span_length_loss_weight_gamma = 0\n",
            "2022-08-19 08:19:37,904 - INFO - allennlp.common.params - relation.use_bag_pair_scorer = False\n",
            "2022-08-19 08:19:37,904 - INFO - allennlp.common.params - relation.use_bi_affine_v2 = False\n",
            "2022-08-19 08:19:37,905 - INFO - allennlp.common.params - relation.use_pruning = True\n",
            "2022-08-19 08:19:37,905 - INFO - allennlp.common.params - relation.use_single_pool = False\n",
            "{'unused_keys': dict_keys(['focal_loss_gamma', 'use_bi_affine_pruner', 'use_classify_mask_pruner', 'use_focal_loss', 'use_ner_scores_for_prune', 'use_ope_down_project', 'use_pair_feature_multiply', 'use_pairwise_down_project', 'use_span_loss_for_pruners', 'use_span_pair_aux_task', 'use_span_pair_aux_task_after_prune'])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f69a951de60>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pair_feature_maxpool': False, 'use_pair_feature_cls': False, 'use_bi_affine_classifier': False, 'neg_class_weight': -1, 'span_length_loss_weight_gamma': 0, 'use_bag_pair_scorer': False, 'use_bi_affine_v2': False, 'use_pruning': True, 'use_single_pool': False, 'kwargs': {'focal_loss_gamma': 2, 'use_bi_affine_pruner': False, 'use_classify_mask_pruner': False, 'use_focal_loss': False, 'use_ner_scores_for_prune': False, 'use_ope_down_project': False, 'use_pair_feature_multiply': False, 'use_pairwise_down_project': False, 'use_span_loss_for_pruners': False, 'use_span_pair_aux_task': False, 'use_span_pair_aux_task_after_prune': False}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__tag_labels, Size: 9 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*tags', '*labels'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n",
            "2022-08-19 08:19:37,923 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-08-19 08:19:37,923 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
            "2022-08-19 08:19:37,927 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
            "2022-08-19 08:19:37,928 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
            "2022-08-19 08:19:37,928 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
            "2022-08-19 08:19:37,928 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-08-19 08:19:37,928 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-08-19 08:19:37,928 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-08-19 08:19:37,928 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-08-19 08:19:37,929 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-08-19 08:19:37,929 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
            "2022-08-19 08:19:37,929 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
            "2022-08-19 08:19:37,937 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
            "2022-08-19 08:19:37,938 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
            "2022-08-19 08:19:37,938 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
            "2022-08-19 08:19:37,938 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-08-19 08:19:37,938 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-08-19 08:19:37,938 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-08-19 08:19:37,938 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
            "2022-08-19 08:19:37,938 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-08-19 08:19:37,939 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer\n",
            "2022-08-19 08:19:37,942 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-08-19 08:19:37,942 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
            "2022-08-19 08:19:37,942 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
            "2022-08-19 08:19:37,942 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
            "2022-08-19 08:19:37,942 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,944 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-08-19 08:19:37,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-08-19 08:19:37,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-08-19 08:19:37,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-08-19 08:19:37,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2022-08-19 08:19:37,953 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-08-19 08:19:37,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
            "2022-08-19 08:19:37,956 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
            "2022-08-19 08:19:37,957 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
            "2022-08-19 08:19:37,957 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n",
            "2022-08-19 08:19:37,958 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-08-19 08:19:37,958 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-08-19 08:19:37,958 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-08-19 08:19:37,959 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-08-19 08:19:37,959 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-08-19 08:19:37,959 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-08-19 08:19:37,959 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-08-19 08:19:37,959 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-08-19 08:19:37,959 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-08-19 08:19:37,959 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-08-19 08:19:37,960 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-08-19 08:19:37,960 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-08-19 08:19:37,960 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-08-19 08:19:37,960 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-08-19 08:19:37,961 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-08-19 08:19:37,961 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-08-19 08:19:37,961 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-08-19 08:19:37,962 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-08-19 08:19:37,962 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-08-19 08:19:37,962 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-08-19 08:19:37,962 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-08-19 08:19:37,962 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-08-19 08:19:37,962 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-08-19 08:19:37,962 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-08-19 08:19:37,962 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-08-19 08:19:37,963 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-08-19 08:19:37,963 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-08-19 08:19:37,963 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-08-19 08:19:37,963 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-08-19 08:19:37,964 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-08-19 08:19:37,964 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-08-19 08:19:37,964 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-08-19 08:19:37,964 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-08-19 08:19:37,964 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-08-19 08:19:37,965 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-08-19 08:19:37,965 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-08-19 08:19:37,965 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-08-19 08:19:37,965 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-08-19 08:19:37,965 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-08-19 08:19:37,965 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-08-19 08:19:37,966 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-08-19 08:19:37,966 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-08-19 08:19:37,966 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
            "2022-08-19 08:19:37,967 - INFO - allennlp.common.params - trainer.patience = None\n",
            "2022-08-19 08:19:37,967 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__relation_f1\n",
            "2022-08-19 08:19:37,967 - INFO - allennlp.common.params - trainer.num_epochs = 10\n",
            "2022-08-19 08:19:37,967 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2022-08-19 08:19:37,968 - INFO - allennlp.common.params - trainer.grad_norm = 5\n",
            "2022-08-19 08:19:37,968 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
            "2022-08-19 08:19:37,968 - INFO - allennlp.common.params - trainer.distributed = False\n",
            "2022-08-19 08:19:37,968 - INFO - allennlp.common.params - trainer.world_size = 1\n",
            "2022-08-19 08:19:37,968 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
            "2022-08-19 08:19:37,968 - INFO - allennlp.common.params - trainer.use_amp = False\n",
            "2022-08-19 08:19:37,968 - INFO - allennlp.common.params - trainer.no_grad = None\n",
            "2022-08-19 08:19:37,969 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
            "2022-08-19 08:19:37,969 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f69ae06fcd0>\n",
            "2022-08-19 08:19:37,969 - INFO - allennlp.common.params - trainer.moving_average = None\n",
            "2022-08-19 08:19:37,969 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
            "2022-08-19 08:19:37,969 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
            "2022-08-19 08:19:37,969 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
            "2022-08-19 08:19:37,970 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
            "2022-08-19 08:19:41,067 - INFO - allennlp.common.params - trainer.optimizer.type = adamw\n",
            "2022-08-19 08:19:41,069 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\n",
            "2022-08-19 08:19:41,069 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
            "2022-08-19 08:19:41,069 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
            "2022-08-19 08:19:41,069 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0\n",
            "2022-08-19 08:19:41,069 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
            "2022-08-19 08:19:41,071 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
            "2022-08-19 08:19:41,071 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}\n",
            "2022-08-19 08:19:41,072 - INFO - allennlp.training.optimizers - Group 1: [], {'lr': 0.01}\n",
            "2022-08-19 08:19:41,072 - INFO - allennlp.training.optimizers - Group 2: ['_relation._relation_scorers.None__relation_labels.weight', '_endpoint_span_extractor._span_width_embedding.weight', '_relation._relation_scorers.None__relation_labels.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight', '_ner._ner_scorers.None__ner_labels.1._module.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight', '_relation.d_embedder.embedder.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias', '_ner._ner_scorers.None__ner_labels.1._module.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight'], {}\n",
            "2022-08-19 08:19:41,072 - WARNING - allennlp.training.optimizers - When constructing parameter groups, scalar_parameters does not match any parameter name\n",
            "2022-08-19 08:19:41,073 - INFO - allennlp.training.optimizers - Number of trainable parameters: 110249737\n",
            "2022-08-19 08:19:41,076 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
            "2022-08-19 08:19:41,078 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
            "2022-08-19 08:19:41,078 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight\n",
            "2022-08-19 08:19:41,078 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
            "2022-08-19 08:19:41,078 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
            "2022-08-19 08:19:41,078 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2022-08-19 08:19:41,079 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
            "2022-08-19 08:19:41,079 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
            "2022-08-19 08:19:41,079 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-08-19 08:19:41,079 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-08-19 08:19:41,079 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-08-19 08:19:41,079 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-08-19 08:19:41,079 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-08-19 08:19:41,079 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-08-19 08:19:41,080 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,080 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,080 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,080 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,080 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,080 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,080 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2022-08-19 08:19:41,080 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2022-08-19 08:19:41,080 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,080 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,081 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-08-19 08:19:41,081 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-08-19 08:19:41,081 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-08-19 08:19:41,081 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-08-19 08:19:41,081 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-08-19 08:19:41,081 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-08-19 08:19:41,081 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,081 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,082 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,082 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,082 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,082 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,082 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2022-08-19 08:19:41,082 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2022-08-19 08:19:41,082 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,082 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,082 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-08-19 08:19:41,082 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-08-19 08:19:41,083 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-08-19 08:19:41,083 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-08-19 08:19:41,083 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-08-19 08:19:41,083 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-08-19 08:19:41,083 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,083 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,083 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,083 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,083 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,084 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,084 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2022-08-19 08:19:41,084 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2022-08-19 08:19:41,084 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,084 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,084 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-08-19 08:19:41,084 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-08-19 08:19:41,084 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-08-19 08:19:41,084 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2022-08-19 08:19:41,085 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,086 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,086 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-08-19 08:19:41,086 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-08-19 08:19:41,086 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-08-19 08:19:41,086 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-08-19 08:19:41,086 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-08-19 08:19:41,086 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-08-19 08:19:41,086 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,086 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,086 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,087 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,087 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,087 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,087 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2022-08-19 08:19:41,087 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2022-08-19 08:19:41,087 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,087 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,087 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-08-19 08:19:41,087 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-08-19 08:19:41,087 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-08-19 08:19:41,088 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-08-19 08:19:41,088 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-08-19 08:19:41,088 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-08-19 08:19:41,088 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,088 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,088 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,088 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,088 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,088 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,088 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2022-08-19 08:19:41,089 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2022-08-19 08:19:41,089 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,089 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,089 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-08-19 08:19:41,089 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-08-19 08:19:41,089 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-08-19 08:19:41,089 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-08-19 08:19:41,089 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-08-19 08:19:41,089 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-08-19 08:19:41,090 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,090 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,090 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,090 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,090 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,090 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,090 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2022-08-19 08:19:41,090 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2022-08-19 08:19:41,090 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,091 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-08-19 08:19:41,092 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,093 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,094 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,095 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,096 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,096 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,096 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,096 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,096 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2022-08-19 08:19:41,096 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2022-08-19 08:19:41,096 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,096 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,096 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-08-19 08:19:41,097 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-08-19 08:19:41,098 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.weight\n",
            "2022-08-19 08:19:41,099 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-08-19 08:19:41,099 - INFO - allennlp.common.util - _relation.d_embedder.embedder.weight\n",
            "2022-08-19 08:19:41,099 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
            "2022-08-19 08:19:41,099 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-08-19 08:19:41,099 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
            "2022-08-19 08:19:41,099 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-08-19 08:19:41,099 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.weight\n",
            "2022-08-19 08:19:41,099 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.bias\n",
            "2022-08-19 08:19:41,100 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
            "2022-08-19 08:19:41,100 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1\n",
            "2022-08-19 08:19:41,100 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32\n",
            "2022-08-19 08:19:41,100 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\n",
            "2022-08-19 08:19:41,100 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\n",
            "2022-08-19 08:19:41,101 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\n",
            "2022-08-19 08:19:41,101 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\n",
            "2022-08-19 08:19:41,101 - INFO - allennlp.common.params - trainer.checkpointer.type = default\n",
            "2022-08-19 08:19:41,101 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None\n",
            "2022-08-19 08:19:41,101 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 1\n",
            "2022-08-19 08:19:41,102 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None\n",
            "2022-08-19 08:19:41,102 - INFO - allennlp.common.params - summary_interval = 100\n",
            "2022-08-19 08:19:41,102 - INFO - allennlp.common.params - histogram_interval = None\n",
            "2022-08-19 08:19:41,102 - INFO - allennlp.common.params - batch_size_interval = None\n",
            "2022-08-19 08:19:41,102 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
            "2022-08-19 08:19:41,102 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
            "2022-08-19 08:19:41,102 - INFO - allennlp.common.params - get_batch_num_total = None\n",
            "2022-08-19 08:19:41,107 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
            "2022-08-19 08:19:41,107 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2022-08-19 08:19:41,108 - INFO - allennlp.training.trainer - Epoch 0/9\n",
            "2022-08-19 08:19:41,108 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.9G\n",
            "2022-08-19 08:19:41,108 - INFO - allennlp.training.trainer - GPU 0 memory usage: 422M\n",
            "2022-08-19 08:19:41,109 - INFO - allennlp.training.trainer - Training\n",
            "2022-08-19 08:19:41,309 - WARNING - allennlp.training.util - Metrics with names beginning with \"_\" will not be logged to the tqdm progress bar.\n",
            "2022-08-19 08:21:09,802 - INFO - allennlp.training.trainer - Validating\n",
            "2022-08-19 08:21:14,933 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-08-19 08:21:14,934 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.063  |     0.150\n",
            "2022-08-19 08:21:14,934 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.112  |     0.690\n",
            "2022-08-19 08:21:14,935 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.044  |     0.084\n",
            "2022-08-19 08:21:14,935 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.293  |     0.708\n",
            "2022-08-19 08:21:14,935 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.264  |     0.856\n",
            "2022-08-19 08:21:14,936 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.330  |     0.603\n",
            "2022-08-19 08:21:14,936 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.293  |     0.708\n",
            "2022-08-19 08:21:14,936 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.264  |     0.856\n",
            "2022-08-19 08:21:14,936 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.330  |     0.603\n",
            "2022-08-19 08:21:14,937 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.063  |     0.150\n",
            "2022-08-19 08:21:14,939 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.112  |     0.690\n",
            "2022-08-19 08:21:14,940 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.044  |     0.084\n",
            "2022-08-19 08:21:14,941 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |   421.803  |       N/A\n",
            "2022-08-19 08:21:14,942 - INFO - allennlp.training.tensorboard_writer - loss                      |    19.768  |    11.338\n",
            "2022-08-19 08:21:14,942 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4034.609  |       N/A\n",
            "2022-08-19 08:21:17,820 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-08-19 08:21:19,708 - INFO - allennlp.training.trainer - Epoch duration: 0:01:38.600405\n",
            "2022-08-19 08:21:19,709 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:14:47\n",
            "2022-08-19 08:21:19,709 - INFO - allennlp.training.trainer - Epoch 1/9\n",
            "2022-08-19 08:21:19,710 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-08-19 08:21:19,710 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-08-19 08:21:19,712 - INFO - allennlp.training.trainer - Training\n",
            "2022-08-19 08:22:46,863 - INFO - allennlp.training.trainer - Validating\n",
            "2022-08-19 08:22:51,834 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-08-19 08:22:51,836 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.369  |     0.514\n",
            "2022-08-19 08:22:51,837 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.505  |     0.466\n",
            "2022-08-19 08:22:51,838 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.291  |     0.574\n",
            "2022-08-19 08:22:51,839 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.748  |     0.789\n",
            "2022-08-19 08:22:51,840 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.780  |     0.763\n",
            "2022-08-19 08:22:51,841 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.718  |     0.817\n",
            "2022-08-19 08:22:51,842 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.748  |     0.789\n",
            "2022-08-19 08:22:51,842 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.780  |     0.763\n",
            "2022-08-19 08:22:51,843 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.718  |     0.817\n",
            "2022-08-19 08:22:51,844 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.369  |     0.514\n",
            "2022-08-19 08:22:51,845 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.505  |     0.466\n",
            "2022-08-19 08:22:51,846 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.291  |     0.574\n",
            "2022-08-19 08:22:51,847 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-08-19 08:22:51,848 - INFO - allennlp.training.tensorboard_writer - loss                      |     9.951  |     9.619\n",
            "2022-08-19 08:22:51,848 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4148.316  |       N/A\n",
            "2022-08-19 08:22:54,800 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-08-19 08:22:56,739 - INFO - allennlp.training.trainer - Epoch duration: 0:01:37.029609\n",
            "2022-08-19 08:22:56,739 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:13:02\n",
            "2022-08-19 08:22:56,739 - INFO - allennlp.training.trainer - Epoch 2/9\n",
            "2022-08-19 08:22:56,739 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-08-19 08:22:56,740 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-08-19 08:22:56,741 - INFO - allennlp.training.trainer - Training\n",
            "2022-08-19 08:24:23,692 - INFO - allennlp.training.trainer - Validating\n",
            "2022-08-19 08:24:28,623 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-08-19 08:24:28,625 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.572  |     0.518\n",
            "2022-08-19 08:24:28,626 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.634  |     0.655\n",
            "2022-08-19 08:24:28,627 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.521  |     0.429\n",
            "2022-08-19 08:24:28,628 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.858  |     0.783\n",
            "2022-08-19 08:24:28,629 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.880  |     0.807\n",
            "2022-08-19 08:24:28,630 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.838  |     0.760\n",
            "2022-08-19 08:24:28,631 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.858  |     0.783\n",
            "2022-08-19 08:24:28,631 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.880  |     0.807\n",
            "2022-08-19 08:24:28,632 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.838  |     0.760\n",
            "2022-08-19 08:24:28,633 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.572  |     0.518\n",
            "2022-08-19 08:24:28,634 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.634  |     0.655\n",
            "2022-08-19 08:24:28,635 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.521  |     0.429\n",
            "2022-08-19 08:24:28,636 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-08-19 08:24:28,636 - INFO - allennlp.training.tensorboard_writer - loss                      |     7.265  |    12.656\n",
            "2022-08-19 08:24:28,637 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4148.316  |       N/A\n",
            "2022-08-19 08:24:31,497 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-08-19 08:24:33,501 - INFO - allennlp.training.trainer - Epoch duration: 0:01:36.761414\n",
            "2022-08-19 08:24:33,501 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:11:22\n",
            "2022-08-19 08:24:33,501 - INFO - allennlp.training.trainer - Epoch 3/9\n",
            "2022-08-19 08:24:33,501 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-08-19 08:24:33,502 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-08-19 08:24:33,503 - INFO - allennlp.training.trainer - Training\n",
            "2022-08-19 08:26:00,041 - INFO - allennlp.training.trainer - Validating\n",
            "2022-08-19 08:26:04,981 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-08-19 08:26:04,982 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.674  |     0.540\n",
            "2022-08-19 08:26:04,982 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.725  |     0.711\n",
            "2022-08-19 08:26:04,983 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.629  |     0.435\n",
            "2022-08-19 08:26:04,984 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.914  |     0.794\n",
            "2022-08-19 08:26:04,986 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.934  |     0.799\n",
            "2022-08-19 08:26:04,987 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.894  |     0.788\n",
            "2022-08-19 08:26:04,987 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.914  |     0.794\n",
            "2022-08-19 08:26:04,988 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.934  |     0.799\n",
            "2022-08-19 08:26:04,989 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.894  |     0.788\n",
            "2022-08-19 08:26:04,990 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.674  |     0.540\n",
            "2022-08-19 08:26:04,991 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.725  |     0.711\n",
            "2022-08-19 08:26:04,992 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.629  |     0.435\n",
            "2022-08-19 08:26:04,993 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-08-19 08:26:04,993 - INFO - allennlp.training.tensorboard_writer - loss                      |     5.980  |    12.632\n",
            "2022-08-19 08:26:04,994 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4148.316  |       N/A\n",
            "2022-08-19 08:26:07,924 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-08-19 08:26:09,971 - INFO - allennlp.training.trainer - Epoch duration: 0:01:36.470080\n",
            "2022-08-19 08:26:09,971 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:09:43\n",
            "2022-08-19 08:26:09,972 - INFO - allennlp.training.trainer - Epoch 4/9\n",
            "2022-08-19 08:26:09,972 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-08-19 08:26:09,972 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-08-19 08:26:09,975 - INFO - allennlp.training.trainer - Training\n",
            "2022-08-19 08:27:36,318 - INFO - allennlp.training.trainer - Validating\n",
            "2022-08-19 08:27:41,209 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-08-19 08:27:41,209 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.718  |     0.465\n",
            "2022-08-19 08:27:41,210 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.751  |     0.767\n",
            "2022-08-19 08:27:41,211 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.688  |     0.333\n",
            "2022-08-19 08:27:41,212 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.946  |     0.796\n",
            "2022-08-19 08:27:41,213 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.957  |     0.766\n",
            "2022-08-19 08:27:41,214 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.936  |     0.828\n",
            "2022-08-19 08:27:41,215 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.946  |     0.796\n",
            "2022-08-19 08:27:41,216 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.957  |     0.766\n",
            "2022-08-19 08:27:41,217 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.936  |     0.828\n",
            "2022-08-19 08:27:41,218 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.718  |     0.465\n",
            "2022-08-19 08:27:41,219 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.751  |     0.767\n",
            "2022-08-19 08:27:41,220 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.688  |     0.333\n",
            "2022-08-19 08:27:41,220 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-08-19 08:27:41,221 - INFO - allennlp.training.tensorboard_writer - loss                      |     4.442  |    12.614\n",
            "2022-08-19 08:27:41,222 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4148.316  |       N/A\n",
            "2022-08-19 08:27:44,331 - INFO - allennlp.training.trainer - Epoch duration: 0:01:34.358925\n",
            "2022-08-19 08:27:44,331 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:08:03\n",
            "2022-08-19 08:27:44,331 - INFO - allennlp.training.trainer - Epoch 5/9\n",
            "2022-08-19 08:27:44,331 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-08-19 08:27:44,331 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-08-19 08:27:44,333 - INFO - allennlp.training.trainer - Training\n",
            "2022-08-19 08:29:09,586 - INFO - allennlp.training.trainer - Validating\n",
            "2022-08-19 08:29:14,477 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-08-19 08:29:14,478 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.791  |     0.598\n",
            "2022-08-19 08:29:14,478 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.813  |     0.696\n",
            "2022-08-19 08:29:14,479 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.771  |     0.525\n",
            "2022-08-19 08:29:14,481 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.965  |     0.793\n",
            "2022-08-19 08:29:14,482 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.971  |     0.790\n",
            "2022-08-19 08:29:14,482 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.958  |     0.797\n",
            "2022-08-19 08:29:14,483 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.965  |     0.793\n",
            "2022-08-19 08:29:14,484 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.971  |     0.790\n",
            "2022-08-19 08:29:14,485 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.958  |     0.797\n",
            "2022-08-19 08:29:14,486 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.791  |     0.598\n",
            "2022-08-19 08:29:14,487 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.813  |     0.696\n",
            "2022-08-19 08:29:14,488 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.771  |     0.525\n",
            "2022-08-19 08:29:14,488 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-08-19 08:29:14,489 - INFO - allennlp.training.tensorboard_writer - loss                      |     3.283  |    16.626\n",
            "2022-08-19 08:29:14,490 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4148.316  |       N/A\n",
            "2022-08-19 08:29:17,433 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-08-19 08:29:19,506 - INFO - allennlp.training.trainer - Epoch duration: 0:01:35.174928\n",
            "2022-08-19 08:29:19,507 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:06:25\n",
            "2022-08-19 08:29:19,507 - INFO - allennlp.training.trainer - Epoch 6/9\n",
            "2022-08-19 08:29:19,507 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-08-19 08:29:19,508 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-08-19 08:29:19,509 - INFO - allennlp.training.trainer - Training\n",
            "2022-08-19 08:30:44,953 - INFO - allennlp.training.trainer - Validating\n",
            "2022-08-19 08:30:49,866 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-08-19 08:30:49,866 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.817  |     0.572\n",
            "2022-08-19 08:30:49,868 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.830  |     0.605\n",
            "2022-08-19 08:30:49,868 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.803  |     0.542\n",
            "2022-08-19 08:30:49,869 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.969  |     0.795\n",
            "2022-08-19 08:30:49,870 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.973  |     0.776\n",
            "2022-08-19 08:30:49,871 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.966  |     0.815\n",
            "2022-08-19 08:30:49,872 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.969  |     0.795\n",
            "2022-08-19 08:30:49,873 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.973  |     0.776\n",
            "2022-08-19 08:30:49,874 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.966  |     0.815\n",
            "2022-08-19 08:30:49,875 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.817  |     0.572\n",
            "2022-08-19 08:30:49,876 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.830  |     0.605\n",
            "2022-08-19 08:30:49,877 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.803  |     0.542\n",
            "2022-08-19 08:30:49,877 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-08-19 08:30:49,878 - INFO - allennlp.training.tensorboard_writer - loss                      |     2.618  |    19.840\n",
            "2022-08-19 08:30:49,879 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4148.316  |       N/A\n",
            "2022-08-19 08:30:52,905 - INFO - allennlp.training.trainer - Epoch duration: 0:01:33.397129\n",
            "2022-08-19 08:30:52,906 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:47\n",
            "2022-08-19 08:30:52,906 - INFO - allennlp.training.trainer - Epoch 7/9\n",
            "2022-08-19 08:30:52,906 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-08-19 08:30:52,907 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-08-19 08:30:52,908 - INFO - allennlp.training.trainer - Training\n",
            "2022-08-19 08:32:18,227 - INFO - allennlp.training.trainer - Validating\n",
            "2022-08-19 08:32:23,266 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-08-19 08:32:23,267 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.877  |     0.609\n",
            "2022-08-19 08:32:23,268 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.895  |     0.593\n",
            "2022-08-19 08:32:23,268 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.861  |     0.626\n",
            "2022-08-19 08:32:23,268 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.985  |     0.790\n",
            "2022-08-19 08:32:23,269 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.989  |     0.746\n",
            "2022-08-19 08:32:23,271 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.980  |     0.838\n",
            "2022-08-19 08:32:23,273 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.985  |     0.790\n",
            "2022-08-19 08:32:23,274 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.989  |     0.746\n",
            "2022-08-19 08:32:23,275 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.980  |     0.838\n",
            "2022-08-19 08:32:23,276 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.877  |     0.609\n",
            "2022-08-19 08:32:23,277 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.895  |     0.593\n",
            "2022-08-19 08:32:23,278 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.861  |     0.626\n",
            "2022-08-19 08:32:23,279 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-08-19 08:32:23,280 - INFO - allennlp.training.tensorboard_writer - loss                      |     1.604  |    23.710\n",
            "2022-08-19 08:32:23,280 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4148.316  |       N/A\n",
            "2022-08-19 08:32:26,242 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-08-19 08:32:28,291 - INFO - allennlp.training.trainer - Epoch duration: 0:01:35.384577\n",
            "2022-08-19 08:32:28,296 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:11\n",
            "2022-08-19 08:32:28,296 - INFO - allennlp.training.trainer - Epoch 8/9\n",
            "2022-08-19 08:32:28,297 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-08-19 08:32:28,298 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-08-19 08:32:28,301 - INFO - allennlp.training.trainer - Training\n",
            "2022-08-19 08:33:52,956 - INFO - allennlp.training.trainer - Validating\n",
            "2022-08-19 08:33:57,933 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-08-19 08:33:57,934 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.914  |     0.601\n",
            "2022-08-19 08:33:57,935 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.914  |     0.574\n",
            "2022-08-19 08:33:57,935 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.915  |     0.632\n",
            "2022-08-19 08:33:57,935 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.987  |     0.791\n",
            "2022-08-19 08:33:57,936 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.989  |     0.749\n",
            "2022-08-19 08:33:57,939 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.986  |     0.838\n",
            "2022-08-19 08:33:57,939 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.987  |     0.791\n",
            "2022-08-19 08:33:57,940 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.989  |     0.749\n",
            "2022-08-19 08:33:57,941 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.986  |     0.838\n",
            "2022-08-19 08:33:57,942 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.914  |     0.601\n",
            "2022-08-19 08:33:57,943 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.914  |     0.574\n",
            "2022-08-19 08:33:57,944 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.915  |     0.632\n",
            "2022-08-19 08:33:57,945 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.912  |       N/A\n",
            "2022-08-19 08:33:57,945 - INFO - allennlp.training.tensorboard_writer - loss                      |     1.274  |    26.459\n",
            "2022-08-19 08:33:57,946 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4148.316  |       N/A\n",
            "2022-08-19 08:34:01,056 - INFO - allennlp.training.trainer - Epoch duration: 0:01:32.759915\n",
            "2022-08-19 08:34:01,058 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:01:35\n",
            "2022-08-19 08:34:01,059 - INFO - allennlp.training.trainer - Epoch 9/9\n",
            "2022-08-19 08:34:01,060 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-08-19 08:34:01,062 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-08-19 08:34:01,064 - INFO - allennlp.training.trainer - Training\n",
            "2022-08-19 08:35:25,105 - INFO - allennlp.training.trainer - Validating\n",
            "2022-08-19 08:35:30,070 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-08-19 08:35:30,071 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.947  |     0.628\n",
            "2022-08-19 08:35:30,071 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.949  |     0.666\n",
            "2022-08-19 08:35:30,071 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.945  |     0.594\n",
            "2022-08-19 08:35:30,071 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.993  |     0.804\n",
            "2022-08-19 08:35:30,072 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.994  |     0.781\n",
            "2022-08-19 08:35:30,072 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.992  |     0.828\n",
            "2022-08-19 08:35:30,072 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.993  |     0.804\n",
            "2022-08-19 08:35:30,073 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.994  |     0.781\n",
            "2022-08-19 08:35:30,073 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.992  |     0.828\n",
            "2022-08-19 08:35:30,076 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.947  |     0.628\n",
            "2022-08-19 08:35:30,078 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.949  |     0.666\n",
            "2022-08-19 08:35:30,079 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.945  |     0.594\n",
            "2022-08-19 08:35:30,079 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.912  |       N/A\n",
            "2022-08-19 08:35:30,080 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.881  |    27.431\n",
            "2022-08-19 08:35:30,081 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4148.316  |       N/A\n",
            "2022-08-19 08:35:32,985 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-08-19 08:35:35,047 - INFO - allennlp.training.trainer - Epoch duration: 0:01:33.987887\n",
            "2022-08-19 08:35:35,048 - INFO - allennlp.training.checkpointer - loading best weights\n",
            "2022-08-19 08:35:35,535 - INFO - allennlp.commands.train - To evaluate on the test set after training, pass the 'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\n",
            "2022-08-19 08:35:35,537 - INFO - allennlp.common.util - Metrics: {\n",
            "\"best_epoch\": 9,\n",
            "\"peak_worker_0_memory_MB\": 4148.31640625,\n",
            "\"peak_gpu_0_memory_MB\": 1871.91162109375,\n",
            "\"training_duration\": \"0:15:48.973650\",\n",
            "\"training_start_epoch\": 0,\n",
            "\"training_epochs\": 9,\n",
            "\"epoch\": 9,\n",
            "\"training__None__ner_precision\": 0.9937106918238994,\n",
            "\"training__None__ner_recall\": 0.9921507064364207,\n",
            "\"training__None__ner_f1\": 0.9929300864100549,\n",
            "\"training__MEAN__ner_precision\": 0.9937106918238994,\n",
            "\"training__MEAN__ner_recall\": 0.9921507064364207,\n",
            "\"training__MEAN__ner_f1\": 0.9929300864100549,\n",
            "\"training__None__relation_precision\": 0.9491059147180193,\n",
            "\"training__None__relation_recall\": 0.9452054794520548,\n",
            "\"training__None__relation_f1\": 0.9471516815374057,\n",
            "\"training_MEAN__relation_precision\": 0.9491059147180193,\n",
            "\"training_MEAN__relation_recall\": 0.9452054794520548,\n",
            "\"training_MEAN__relation_f1\": 0.9471516815374057,\n",
            "\"training_loss\": 0.8812927639323082,\n",
            "\"training_worker_0_memory_MB\": 4148.31640625,\n",
            "\"training_gpu_0_memory_MB\": 1871.91162109375,\n",
            "\"validation__None__ner_precision\": 0.7814465408805031,\n",
            "\"validation__None__ner_recall\": 0.8283333333333334,\n",
            "\"validation__None__ner_f1\": 0.8042071197411004,\n",
            "\"validation__MEAN__ner_precision\": 0.7814465408805031,\n",
            "\"validation__MEAN__ner_recall\": 0.8283333333333334,\n",
            "\"validation__MEAN__ner_f1\": 0.8042071197411004,\n",
            "\"validation__None__relation_precision\": 0.6655844155844156,\n",
            "\"validation__None__relation_recall\": 0.5942028985507246,\n",
            "\"validation__None__relation_f1\": 0.6278713629402756,\n",
            "\"validation_MEAN__relation_precision\": 0.6655844155844156,\n",
            "\"validation_MEAN__relation_recall\": 0.5942028985507246,\n",
            "\"validation_MEAN__relation_f1\": 0.6278713629402756,\n",
            "\"validation_loss\": 27.431374580232433,\n",
            "\"best_validation__None__ner_precision\": 0.7814465408805031,\n",
            "\"best_validation__None__ner_recall\": 0.8283333333333334,\n",
            "\"best_validation__None__ner_f1\": 0.8042071197411004,\n",
            "\"best_validation__MEAN__ner_precision\": 0.7814465408805031,\n",
            "\"best_validation__MEAN__ner_recall\": 0.8283333333333334,\n",
            "\"best_validation__MEAN__ner_f1\": 0.8042071197411004,\n",
            "\"best_validation__None__relation_precision\": 0.6655844155844156,\n",
            "\"best_validation__None__relation_recall\": 0.5942028985507246,\n",
            "\"best_validation__None__relation_f1\": 0.6278713629402756,\n",
            "\"best_validation_MEAN__relation_precision\": 0.6655844155844156,\n",
            "\"best_validation_MEAN__relation_recall\": 0.5942028985507246,\n",
            "\"best_validation_MEAN__relation_f1\": 0.6278713629402756,\n",
            "\"best_validation_loss\": 27.431374580232433\n",
            "}\n",
            "2022-08-19 08:35:35,544 - INFO - allennlp.models.archival - archiving weights and vocabulary to outputs/14lap/seed_4/weights/model.tar.gz\n"
          ]
        }
      ],
      "source": [
        "# Train SpanModel from scratch\n",
        "random_seed = 4\n",
        "path_train = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
        "path_dev = f\"aste/data/triplet_data/{data_name}/dev.txt\"\n",
        "path_test = f\"aste/data/triplet_data/{data_name}/test.txt\"\n",
        "save_dir = f\"outputs/{data_name}/seed_{random_seed}\"\n",
        "\n",
        "model = SpanModel(save_dir=save_dir, random_seed=random_seed)\n",
        "model.fit(path_train, path_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjyiKWjSF7oZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de93155-e180-4d05-aca2-2cf6e6eaa90f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'command': 'cd /content && allennlp predict outputs/14lap/seed_4/weights/model.tar.gz /content/outputs/14lap/seed_4/temp_data/pred_in.json --predictor span_model --include-package span_model --use-dataset-reader  --output-file outputs/14lap/seed_4/temp_data/pred_out.json --cuda-device 0 --silent '}\n",
            "################################################################################\n",
            "################################################################################\n",
            "{'locals': ('use_ner_embeds', False)}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_double_mix_embedder', False)}\n",
            "{'locals': ('relation_head_type', 'proper')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "{'unused_keys': dict_keys(['focal_loss_gamma', 'use_bi_affine_pruner', 'use_classify_mask_pruner', 'use_focal_loss', 'use_ner_scores_for_prune', 'use_ope_down_project', 'use_pair_feature_multiply', 'use_pairwise_down_project', 'use_span_loss_for_pruners', 'use_span_pair_aux_task', 'use_span_pair_aux_task_after_prune'])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f94828b9c20>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pair_feature_maxpool': False, 'use_pair_feature_cls': False, 'use_bi_affine_classifier': False, 'neg_class_weight': -1, 'span_length_loss_weight_gamma': 0, 'use_bag_pair_scorer': False, 'use_bi_affine_v2': False, 'use_pruning': True, 'use_single_pool': False, 'kwargs': {'focal_loss_gamma': 2, 'use_bi_affine_pruner': False, 'use_classify_mask_pruner': False, 'use_focal_loss': False, 'use_ner_scores_for_prune': False, 'use_ope_down_project': False, 'use_pair_feature_multiply': False, 'use_pairwise_down_project': False, 'use_span_loss_for_pruners': False, 'use_span_pair_aux_task': False, 'use_span_pair_aux_task_after_prune': False}, 'vocab': Vocabulary with namespaces:  None__tag_labels, Size: 9 || None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n",
            "{'file_path': '/content/outputs/14lap/seed_4/temp_data/pred_in.json', 'stats': Stats(entity_total=328, entity_drop=0, relation_total=328, relation_drop=0, graph_total=0, graph_edges=0, grid_total=110829, grid_paired=328)}\n",
            "{\n",
            "  \"path_pred\": \"pred.txt\",\n",
            "  \"path_gold\": \"aste/data/triplet_data/14lap/test.txt\",\n",
            "  \"precision\": 0.6439232409381663,\n",
            "  \"recall\": 0.5561694290976059,\n",
            "  \"score\": 0.5968379446640316\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate SpanModel F1 Score\n",
        "import json\n",
        "\n",
        "path_pred = \"pred.txt\"\n",
        "model.predict(path_in=path_test, path_out=path_pred)\n",
        "results = model.score(path_pred, path_test)\n",
        "print(json.dumps(results, indent=2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06ce7feacbfc47e696b005bda7d6fc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e7961cebbbd4af988eadca9ebbc72a8",
              "IPY_MODEL_57bf9771c66f48fb89f29c2138d64101",
              "IPY_MODEL_df4cef36d642490eb23f0db462d8acf5"
            ],
            "layout": "IPY_MODEL_ae3a872a5e084ae79d393a45bb4e75bb"
          }
        },
        "7e7961cebbbd4af988eadca9ebbc72a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f989b846ca904d818d1c48c7fc43a301",
            "placeholder": "​",
            "style": "IPY_MODEL_058ba503b3e3485298c0e84b3eb831f7",
            "value": "Downloading: 100%"
          }
        },
        "57bf9771c66f48fb89f29c2138d64101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd916234f834a61b154c6d1cbc16093",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ff50cf0303e4f32b111582a8f1a7204",
            "value": 433
          }
        },
        "df4cef36d642490eb23f0db462d8acf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be21ffc26a88423fa04274598782ca94",
            "placeholder": "​",
            "style": "IPY_MODEL_13ae0428359f4af79ba13401d4b6a671",
            "value": " 433/433 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "ae3a872a5e084ae79d393a45bb4e75bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f989b846ca904d818d1c48c7fc43a301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058ba503b3e3485298c0e84b3eb831f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbd916234f834a61b154c6d1cbc16093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff50cf0303e4f32b111582a8f1a7204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be21ffc26a88423fa04274598782ca94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ae0428359f4af79ba13401d4b6a671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b249aa7368d048a1aa0bb26fef197a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_978289baa03e4a728c91767e682c1e58",
              "IPY_MODEL_53f0e9654c42432c936a7be756c2f1ad",
              "IPY_MODEL_373b2bbdd6094405b5a3781e3ce8b854"
            ],
            "layout": "IPY_MODEL_e17fae11370d48469a43723103510276"
          }
        },
        "978289baa03e4a728c91767e682c1e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2137a1d41bf4654b2321b0e8b3179ea",
            "placeholder": "​",
            "style": "IPY_MODEL_9819a63af0f349f3b7eda83464325600",
            "value": "Downloading: 100%"
          }
        },
        "53f0e9654c42432c936a7be756c2f1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ed85ff4e68d4c258dc7fc7a5eb60a0f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9df7921ab61b4a8698e5dff835fd1ada",
            "value": 231508
          }
        },
        "373b2bbdd6094405b5a3781e3ce8b854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68dcb517716848faaa1196b40d011954",
            "placeholder": "​",
            "style": "IPY_MODEL_9739ad3b7a894a76956a305a5505c84f",
            "value": " 232k/232k [00:00&lt;00:00, 4.69MB/s]"
          }
        },
        "e17fae11370d48469a43723103510276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2137a1d41bf4654b2321b0e8b3179ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9819a63af0f349f3b7eda83464325600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ed85ff4e68d4c258dc7fc7a5eb60a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9df7921ab61b4a8698e5dff835fd1ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68dcb517716848faaa1196b40d011954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9739ad3b7a894a76956a305a5505c84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1759abf000f433dbbcd8e3ace643b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e3e35bc02f9405fb467ba7cd1aee340",
              "IPY_MODEL_3ee51e2dcd654f2caff137cff38f8bc9",
              "IPY_MODEL_13cc94dcb00a470a87aaf3409b20a605"
            ],
            "layout": "IPY_MODEL_c5f32837a20b480eb4f75f7ba357e443"
          }
        },
        "5e3e35bc02f9405fb467ba7cd1aee340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ebd2d576b044d7aac22e3ef1cd7bf49",
            "placeholder": "​",
            "style": "IPY_MODEL_8f1e31c6b0094f6a80da012841845920",
            "value": "Downloading: 100%"
          }
        },
        "3ee51e2dcd654f2caff137cff38f8bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cad43e17e0194a9da9586158788e6757",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32b38abe23a74a569a3fe0895a36d54e",
            "value": 466062
          }
        },
        "13cc94dcb00a470a87aaf3409b20a605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cf108605bd54f87a2ca6a5f505926df",
            "placeholder": "​",
            "style": "IPY_MODEL_b64601c0d3d3465d8334080f24c50138",
            "value": " 466k/466k [00:00&lt;00:00, 8.26MB/s]"
          }
        },
        "c5f32837a20b480eb4f75f7ba357e443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ebd2d576b044d7aac22e3ef1cd7bf49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1e31c6b0094f6a80da012841845920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cad43e17e0194a9da9586158788e6757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b38abe23a74a569a3fe0895a36d54e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cf108605bd54f87a2ca6a5f505926df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64601c0d3d3465d8334080f24c50138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46d6b1110d3d428d940f7b169250313f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f6f97e61db74ac8b351a2836191f15d",
              "IPY_MODEL_119ea25862a6424dbd0281cc394dc215",
              "IPY_MODEL_627a0977de4349019428352c7e9b9243"
            ],
            "layout": "IPY_MODEL_3f6347036fe0464a8aead0d7fec311b2"
          }
        },
        "6f6f97e61db74ac8b351a2836191f15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_343bbfb6096d4dde9b415b7eae198e68",
            "placeholder": "​",
            "style": "IPY_MODEL_c2b9230207404a03b87b1da87978873e",
            "value": "Downloading: 100%"
          }
        },
        "119ea25862a6424dbd0281cc394dc215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afef86df3231491d9ff5ec09b5b7856b",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccb2ccd455ae477d837e36f23bc185ec",
            "value": 440473133
          }
        },
        "627a0977de4349019428352c7e9b9243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3192fada7cdc48719da3f03d31dc52f1",
            "placeholder": "​",
            "style": "IPY_MODEL_68805c09bfc44d86a2f5d99cacc7551f",
            "value": " 440M/440M [00:07&lt;00:00, 56.4MB/s]"
          }
        },
        "3f6347036fe0464a8aead0d7fec311b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "343bbfb6096d4dde9b415b7eae198e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b9230207404a03b87b1da87978873e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afef86df3231491d9ff5ec09b5b7856b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccb2ccd455ae477d837e36f23bc185ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3192fada7cdc48719da3f03d31dc52f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68805c09bfc44d86a2f5d99cacc7551f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}